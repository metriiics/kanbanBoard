from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import Optional
import httpx
from core.config import settings
from core.security import get_current_user
from core.logger import logger

router = APIRouter(tags=["ü§ñ AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"])


class ChatMessage(BaseModel):
    message: str
    model: Optional[str] = None


class ChatResponse(BaseModel):
    response: str
    model: str


@router.post("/api/ai/chat", response_model=ChatResponse)
async def chat_with_ai(
    chat_message: ChatMessage,
    current_user=Depends(get_current_user)
):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ AI –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Ollama –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç.
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        model = chat_message.model or settings.OLLAMA_MODEL
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –æ —Ç–æ–º, —á—Ç–æ —ç—Ç–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏
        system_prompt = """–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ (Kanban –¥–æ—Å–∫–∞). 
–ü–æ–º–æ–≥–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –æ –∑–∞–¥–∞—á–∞—Ö, –ø—Ä–æ–µ–∫—Ç–∞—Ö, —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞—Ö –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–µ–º.
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ –¥–µ–ª—É. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–≤—è–∑–∞–Ω —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –∑–∞–¥–∞—á–∞–º–∏, –≤–µ–∂–ª–∏–≤–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤—å —Ä–∞–∑–≥–æ–≤–æ—Ä."""
        
        user_message = chat_message.message
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama
        ollama_url = f"{settings.OLLAMA_BASE_URL}/api/chat"
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            "stream": False
        }
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(ollama_url, json=payload)
            response.raise_for_status()
            result = response.json()
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ Ollama
        ai_response = result.get("message", {}).get("content", "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI.")
        
        logger.info(f"AI request from user {current_user.id}: {user_message[:50]}...")
        
        return ChatResponse(
            response=ai_response,
            model=model
        )
        
    except httpx.TimeoutException:
        logger.error("Ollama request timeout")
        raise HTTPException(
            status_code=504,
            detail="–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        )
    except httpx.HTTPStatusError as e:
        logger.error(f"Ollama HTTP error: {e.response.status_code} - {e.response.text}")
        if e.response.status_code == 404:
            raise HTTPException(
                status_code=404,
                detail=f"–ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤ Ollama."
            )
        raise HTTPException(
            status_code=502,
            detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Ollama. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞."
        )
    except Exception as e:
        logger.error(f"Unexpected error in AI chat: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"
        )


@router.get("/api/ai/models")
async def get_available_models(
    current_user=Depends(get_current_user)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ Ollama.
    """
    try:
        ollama_url = f"{settings.OLLAMA_BASE_URL}/api/tags"
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(ollama_url)
            response.raise_for_status()
            result = response.json()
        
        models = [model.get("name", "") for model in result.get("models", [])]
        
        return {"models": models}
        
    except httpx.TimeoutException:
        logger.error("Ollama models request timeout")
        raise HTTPException(
            status_code=504,
            detail="–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç Ollama."
        )
    except httpx.HTTPStatusError as e:
        logger.error(f"Ollama HTTP error: {e.response.status_code}")
        raise HTTPException(
            status_code=502,
            detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Ollama. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞."
        )
    except Exception as e:
        logger.error(f"Unexpected error getting models: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"
        )

